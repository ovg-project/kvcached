diff --git a/python/sglang/srt/managers/scheduler.py b/python/sglang/srt/managers/scheduler.py
index 8891115c1..34099c61e 100644
--- a/python/sglang/srt/managers/scheduler.py
+++ b/python/sglang/srt/managers/scheduler.py
@@ -1235,7 +1235,8 @@ class Scheduler(
             if not self.enable_hierarchical_cache
             else self.max_total_num_tokens - protected_size
         )
-        if memory_leak:
+        enable_kvcached = os.getenv("ENABLE_KVCACHED", "false").lower() == "true"
+        if memory_leak and not enable_kvcached:
             msg = (
                 "token_to_kv_pool_allocator memory leak detected! "
                 f"{available_size=}, {protected_size=}, {self.max_total_num_tokens=}\n"
diff --git a/python/sglang/srt/mem_cache/memory_pool.py b/python/sglang/srt/mem_cache/memory_pool.py
index f7eef2120..7e7caca02 100644
--- a/python/sglang/srt/mem_cache/memory_pool.py
+++ b/python/sglang/srt/mem_cache/memory_pool.py
@@ -154,14 +154,26 @@ class TokenToKVPoolAllocator:
         self.clear()
 
         self._kvcache = kvcache
+        self.enable_kvcached = (
+            hasattr(kvcache, "enable_kvcached") and kvcache.enable_kvcached
+        )
+        if self.enable_kvcached:
+            self.kvcached_allocator = kvcache.kvcached_allocator
 
     def available_size(self):
+        if self.enable_kvcached:
+            return self.kvcached_allocator.available_size()
         return len(self.free_slots)
 
     def get_kvcache(self):
         return self._kvcache
 
     def alloc(self, need_size: int):
+        if self.enable_kvcached:
+            indices = self.kvcached_allocator.alloc(need_size)
+            indices = torch.tensor(indices, dtype=torch.int32, device="cuda")
+            return indices
+
         if need_size > len(self.free_slots):
             return None
 
@@ -174,6 +186,8 @@ class TokenToKVPoolAllocator:
             return
 
         if self.is_not_in_free_group:
+            if self.enable_kvcached:
+                return self.kvcached_allocator.free(free_index.cpu().numpy())
             self.free_slots = torch.cat((self.free_slots, free_index))
         else:
             self.free_group.append(free_index)
@@ -194,6 +208,10 @@ class TokenToKVPoolAllocator:
         self.free_slots = free_slots
 
     def clear(self):
+        if hasattr(self, "enable_kvcached") and self.enable_kvcached:
+            self.kvcached_allocator.clear()
+            return
+
         # The padded slot 0 is used for writing dummy outputs from padded tokens.
         self.free_slots = torch.arange(
             1, self.size + 1, dtype=torch.int64, device=self.device
@@ -233,6 +251,30 @@ class MHATokenToKVPool(KVCache):
         self.head_num = head_num
         self.head_dim = head_dim
         self.layer_num = layer_num
+
+        import os  # noqa: E501
+
+        self.enable_kvcached = os.getenv("ENABLE_KVCACHED", "false").lower() == "true"
+        if self.enable_kvcached:
+            try:
+                import kvcached.integration.sglang.interfaces as kvcached_interfaces  # noqa: E501
+
+                self.kvcached_interfaces = kvcached_interfaces
+                self.kvcached_interfaces.init_kvcached()
+
+                # Initialize KV allocator based on per-token KV size (cell_size)
+                self.cell_size = self.head_num * self.head_dim * self.dtype.itemsize
+                self.kvcached_allocator = kvcached_interfaces.get_kv_cache_manager(
+                    self.size,
+                    self.page_size,
+                    self.cell_size,
+                    num_layers=end_layer - start_layer + 1,
+                )
+            except ImportError as e:
+                raise ImportError(
+                    "kvcached is not found. Please install it for elastic memory."
+                ) from e
+
         self._create_buffers()
         self.start_layer = start_layer or 0
         self.end_layer = end_layer or layer_num - 1
@@ -247,7 +289,26 @@ class MHATokenToKVPool(KVCache):
             f"KV Cache is allocated. #tokens: {size}, K size: {k_size / GB:.2f} GB, V size: {v_size / GB:.2f} GB"
         )
 
+    def __del__(self):
+        if self.enable_kvcached and self.kvcached_allocator is not None:
+            self.kvcached_interfaces.shutdown_kvcached()
+            del self.kvcached_allocator
+            self.k_buffer = None
+            self.v_buffer = None
+
     def _create_buffers(self):
+        if self.enable_kvcached:
+            self.k_buffer, self.v_buffer = self.kvcached_interfaces.alloc_kv_cache(
+                self.size,
+                self.head_num,
+                self.head_dim,
+                self.dtype,
+                self.device,
+                self.layer_num,
+                self.page_size,
+            )
+            return
+
         with self.memory_saver_adapter.region():
             # [size, head_num, head_dim] for each layer
             # The padded slot 0 is used for writing dummy outputs from padded tokens.
