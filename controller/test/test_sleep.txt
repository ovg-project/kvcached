Testing SleepManager with Real vLLM Instances
============================================================
This test connects to running vLLM instances on:
  - meta-llama/Llama-3.2-1B at localhost:12346
  - Qwen/Qwen3-0.6B at localhost:12347
============================================================
=== Testing Basic Functionality ===
✓ SleepManager created successfully
  Auto sleep enabled: False
  Idle threshold: 300s
  Wake on request: True
  Min sleep duration: 60s

=== Testing Real vLLM Instances ===
✓ Added 2 real vLLM models:
  meta-llama/Llama-3.2-1B: localhost:12346
  Qwen/Qwen3-0.6B: localhost:12347

=== Testing Sleep/Wake Functionality ===
Testing sleep/wake cycle for meta-llama/Llama-3.2-1B
1. Checking initial sleep status...
   Initial sleep status: False
2. Putting model to sleep...
   Sleep operation success: True
3. Verifying model is sleeping...
   Sleep status after sleep: True
   Internal sleep tracking: True
4. Waiting 60s for minimum sleep duration...
5. Waking up model...
   Wake operation success: True
6. Verifying model is awake...
   Sleep status after wake: False
   Internal sleep tracking: False

=== Testing Sleep State Tracking ===
✓ Currently sleeping models: 0
✓ Sleep candidates: 0

=== Testing Configuration Updates ===
✓ Updated configuration:
  Auto sleep enabled: True
  Idle threshold: 600s
  Min sleep duration: 120s

=== Testing API Method Signatures ===
✓ sleep/wake API methods are properly defined:
  _call_vllm_sleep_api: True
  _call_vllm_wake_api: True
  check_model_sleep_status: True
  handle_request_wake: True

============================================================
✅ All tests completed successfully!

Real vLLM sleep/wake functionality has been tested.
Check the output above for detailed results.
