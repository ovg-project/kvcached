Traffic Monitor & Sleep Management Test Suite
============================================
Make sure the controller server is running!
Expected server URL: http://localhost:8081

To start the server:
  cd /workspace/kvcached/controller
  python frontend.py --config example-config.yaml --port 8081

🚀 Starting Traffic Monitor & Sleep Management Tests
============================================================
Base URL: http://localhost:8081
Test Models: meta-llama/Llama-3.2-1B, Qwen/Qwen3-0.6B
============================================================

🔌 Testing server connectivity...
✅ Server is responding
📋 Available models: meta-llama/Llama-3.2-1B, Qwen/Qwen3-0.6B

📈 Generating 4 test requests...
  Request 1: meta-llama/Llama-3.2-1B - 'Hello, how are you today?...'
  Request 2: meta-llama/Llama-3.2-1B - 'What are the benefits of renew...'
  Request 3: Qwen/Qwen3-0.6B - 'Hello, how are you today?...'
  Request 4: meta-llama/Llama-3.2-1B - 'Explain quantum physics in sim...'

🔍 Testing Traffic Monitoring Endpoints
==================================================

📊 Testing: /traffic/stats
  ✅ Status: 200
  📈 Found stats for 2 models

📊 Testing: /traffic/stats?window=30
  ✅ Status: 200
  📈 Found stats for 2 models

📊 Testing: /traffic/idle
  ✅ Status: 200
  😴 Found 0 idle models

📊 Testing: /traffic/idle?threshold=60
  ✅ Status: 200
  😴 Found 0 idle models

📊 Testing: /traffic/active
  ✅ Status: 200
  ⚡ Found 2 active models

📊 Testing: /traffic/active?threshold=60&window=30
  ✅ Status: 200
  ⚡ Found 2 active models

📊 Testing: /traffic/stats/model/meta-llama%2FLlama-3.2-1B
  ✅ Status: 200
  📊 Model: meta-llama/Llama-3.2-1B
      Requests: 3
      Rate: 0.05 req/s

📊 Testing: /traffic/stats/model/meta-llama%2FLlama-3.2-1B?window=30
  ✅ Status: 200
  📊 Model: meta-llama/Llama-3.2-1B
      Requests: 3
      Rate: 0.10 req/s

📊 Testing: /traffic/stats/model/Qwen%2FQwen3-0.6B
  ✅ Status: 200
  📊 Model: Qwen/Qwen3-0.6B
      Requests: 1
      Rate: 0.02 req/s

📊 Testing: /traffic/stats/model/Qwen%2FQwen3-0.6B?window=30
  ✅ Status: 200
  📊 Model: Qwen/Qwen3-0.6B
      Requests: 1
      Rate: 0.03 req/s

😴 Testing Sleep Management Endpoints
==================================================

🔍 Testing sleep status...
  ✅ Sleep status retrieved
  💤 Sleeping models: 0
  🎯 Sleep candidates: 0
  🔄 Auto-sleep: False

🎯 Testing sleep candidates...
  ✅ Found 0 sleep candidates

💤 Testing manual sleep for model: Qwen/Qwen3-0.6B
!!! Qwen%2FQwen3-0.6B
  ✅ Model put to sleep successfully
  ✅ Model confirmed sleeping

⏰ Testing wake up for model: Qwen/Qwen3-0.6B Qwen%2FQwen3-0.6B
  ✅ Model woken up successfully

🎯 Testing Integration Scenarios
==================================================

📋 Scenario 1: Traffic Generation → Monitoring

📈 Generating 3 test requests...
  Request 1: Qwen/Qwen3-0.6B - 'Hello, how are you today?...'
  Request 2: meta-llama/Llama-3.2-1B - 'Hello, how are you today?...'
  Request 3: Qwen/Qwen3-0.6B - 'What are the benefits of renew...'
  Generated traffic: 3/3 successful requests
  📊 Current stats show 2 models with activity
    - meta-llama/Llama-3.2-1B: 4 requests, 0.07 req/s
    - Qwen/Qwen3-0.6B: 3 requests, 0.05 req/s

📋 Scenario 2: Idle Detection
  Waiting 10 seconds to test idle detection...
  😴 Found 2 models idle for >5 seconds

📋 Scenario 3: Wake-on-Request for meta-llama/Llama-3.2-1B
  Sending request to sleeping model...
  ✅ Request succeeded - wake-on-request working

📊 Test Summary
==============================
Traffic Tests: 10/10 passed
Sleep Tests: 4/4 passed
🎉 All tests passed!
