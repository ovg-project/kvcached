Traffic Monitor & Sleep Management Test Suite
============================================
Make sure the controller server is running!
Expected server URL: http://localhost:8081

To start the server:
  cd /workspace/kvcached/controller
  python frontend.py --config example-config.yaml --port 8081

ğŸš€ Starting Traffic Monitor & Sleep Management Tests
============================================================
Base URL: http://localhost:8081
Test Models: meta-llama/Llama-3.2-1B, Qwen/Qwen3-0.6B
============================================================

ğŸ”Œ Testing server connectivity...
âœ… Server is responding
ğŸ“‹ Available models: meta-llama/Llama-3.2-1B, Qwen/Qwen3-0.6B

ğŸ“ˆ Generating 4 test requests...
  Request 1: meta-llama/Llama-3.2-1B - 'Hello, how are you today?...'
  Request 2: meta-llama/Llama-3.2-1B - 'What are the benefits of renew...'
  Request 3: Qwen/Qwen3-0.6B - 'Hello, how are you today?...'
  Request 4: meta-llama/Llama-3.2-1B - 'Explain quantum physics in sim...'

ğŸ” Testing Traffic Monitoring Endpoints
==================================================

ğŸ“Š Testing: /traffic/stats
  âœ… Status: 200
  ğŸ“ˆ Found stats for 2 models

ğŸ“Š Testing: /traffic/stats?window=30
  âœ… Status: 200
  ğŸ“ˆ Found stats for 2 models

ğŸ“Š Testing: /traffic/idle
  âœ… Status: 200
  ğŸ˜´ Found 0 idle models

ğŸ“Š Testing: /traffic/idle?threshold=60
  âœ… Status: 200
  ğŸ˜´ Found 0 idle models

ğŸ“Š Testing: /traffic/active
  âœ… Status: 200
  âš¡ Found 2 active models

ğŸ“Š Testing: /traffic/active?threshold=60&window=30
  âœ… Status: 200
  âš¡ Found 2 active models

ğŸ“Š Testing: /traffic/stats/model/meta-llama%2FLlama-3.2-1B
  âœ… Status: 200
  ğŸ“Š Model: meta-llama/Llama-3.2-1B
      Requests: 3
      Rate: 0.05 req/s

ğŸ“Š Testing: /traffic/stats/model/meta-llama%2FLlama-3.2-1B?window=30
  âœ… Status: 200
  ğŸ“Š Model: meta-llama/Llama-3.2-1B
      Requests: 3
      Rate: 0.10 req/s

ğŸ“Š Testing: /traffic/stats/model/Qwen%2FQwen3-0.6B
  âœ… Status: 200
  ğŸ“Š Model: Qwen/Qwen3-0.6B
      Requests: 1
      Rate: 0.02 req/s

ğŸ“Š Testing: /traffic/stats/model/Qwen%2FQwen3-0.6B?window=30
  âœ… Status: 200
  ğŸ“Š Model: Qwen/Qwen3-0.6B
      Requests: 1
      Rate: 0.03 req/s

ğŸ˜´ Testing Sleep Management Endpoints
==================================================

ğŸ” Testing sleep status...
  âœ… Sleep status retrieved
  ğŸ’¤ Sleeping models: 0
  ğŸ¯ Sleep candidates: 0
  ğŸ”„ Auto-sleep: False

ğŸ¯ Testing sleep candidates...
  âœ… Found 0 sleep candidates

ğŸ’¤ Testing manual sleep for model: Qwen/Qwen3-0.6B
!!! Qwen%2FQwen3-0.6B
  âœ… Model put to sleep successfully
  âœ… Model confirmed sleeping

â° Testing wake up for model: Qwen/Qwen3-0.6B Qwen%2FQwen3-0.6B
  âœ… Model woken up successfully

ğŸ¯ Testing Integration Scenarios
==================================================

ğŸ“‹ Scenario 1: Traffic Generation â†’ Monitoring

ğŸ“ˆ Generating 3 test requests...
  Request 1: Qwen/Qwen3-0.6B - 'Hello, how are you today?...'
  Request 2: meta-llama/Llama-3.2-1B - 'Hello, how are you today?...'
  Request 3: Qwen/Qwen3-0.6B - 'What are the benefits of renew...'
  Generated traffic: 3/3 successful requests
  ğŸ“Š Current stats show 2 models with activity
    - meta-llama/Llama-3.2-1B: 4 requests, 0.07 req/s
    - Qwen/Qwen3-0.6B: 3 requests, 0.05 req/s

ğŸ“‹ Scenario 2: Idle Detection
  Waiting 10 seconds to test idle detection...
  ğŸ˜´ Found 2 models idle for >5 seconds

ğŸ“‹ Scenario 3: Wake-on-Request for meta-llama/Llama-3.2-1B
  Sending request to sleeping model...
  âœ… Request succeeded - wake-on-request working

ğŸ“Š Test Summary
==============================
Traffic Tests: 10/10 passed
Sleep Tests: 4/4 passed
ğŸ‰ All tests passed!
